from openai import OpenAI
import os
import base64
import sys
from PIL import Image
from io import BytesIO
import httpx

os.environ["http_proxy"] = ""
os.environ["https_proxy"] = ""
url = 'https://mian.456478.xyz/v1'
# url = 'http://8.129.24.9:20000/v1'
# url = 'https://api.openai.com/v1/'
token = os.getenv("OPENAI_API_KEY", "å¡«å…¥token")
if not token:
    print("Error: ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®ï¼")
    sys.exit(1)
model = os.getenv("model_choice", "o3")
if not model:
    print("Error: ç¯å¢ƒå˜é‡ model_choice æœªè®¾ç½®ï¼")
    sys.exit(1)
# model = "qwen3-235b-a22b"
model = "o4-mini"
# model = "o3"
model = "claude-3-7-sonnet-thinking"
# model = "gpt-4.1"

#  base 64 ç¼–ç æ ¼å¼
def encode_image(image_path: str, max_size: int = 480) -> str:
    """
    æ‰“å¼€ image_path æŒ‡å®šçš„å›¾ç‰‡ï¼Œ
    å¦‚æœå®½æˆ–é«˜çš„æœ€å¤§å€¼ > max_sizeï¼Œåˆ™æŒ‰ç­‰æ¯”ç¼©å°åˆ°æœ€é•¿è¾¹ä¸º max_sizeï¼Œ
    ç„¶åè½¬æ¢ä¸º RGB æ¨¡å¼å¹¶ä»¥ JPEG æ ¼å¼ç¼–ç ï¼Œè¿”å› base64 å­—ç¬¦ä¸²ã€‚
    """
    with Image.open(image_path) as img:
        w, h = img.size
        max_dim = max(w, h)
        if max_dim > max_size:
            scale = max_size / max_dim
            new_size = (int(w * scale), int(h * scale))
            img = img.resize(new_size, Image.LANCZOS)

        # å¦‚æœæœ‰é€æ˜é€šé“ï¼Œè½¬æ¢ä¸º RGB
        if img.mode in ("RGBA", "LA") or (img.mode == "P" and "transparency" in img.info):
            img = img.convert("RGB")

        buffer = BytesIO()
        img.save(buffer, format="JPEG")
        return base64.b64encode(buffer.getvalue()).decode("utf-8")

                    
def gpt_infer(image_url, prompt):
    base64_image = encode_image(image_url)
    headers = {'Content-Type': 'application/json'}
    insecure_http_client = httpx.Client(headers=headers, verify=False, follow_redirects=True)  # åŒæ­¥ç‰ˆ
    client = OpenAI(
        api_key=token,
        base_url=url,
        http_client=insecure_http_client
    )
    completion = client.chat.completions.create(
        # model="gpt-4o",
        model=model,
        messages=[
        {"role": "user", "content": [
                # {"type": "image_url", "image_url":f"data:image/jpg;base64,{base64_image}"},
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {
                        "url": f"data:image/jpg;base64,{base64_image}",
                        "detail": "high"
                    },}
        ]}
        ],
        # response_format={"type": "json_object"}
    )
    # print(completion.usage)
    # return completion
    return completion.choices[0].message.content

def gpt_infer_no_image(prompt,model_used = model):
    headers = {'Content-Type': 'application/json'}
    # å®¢æˆ·ç«¯ä¸å†è¶…æ—¶ï¼ˆäº¤ç»™ç½‘å…³å¤„ç†ï¼‰ï¼š
    insecure_http_client = httpx.Client(headers=headers, verify=False, follow_redirects=True, timeout=None)
    client = OpenAI(api_key=token, base_url=url, http_client=insecure_http_client)
    print('ğŸ˜ƒä½¿ç”¨æ¨¡å‹è°ƒç”¨ä¸­',model_used)
    completion = client.chat.completions.create(
        model=model_used,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=70000,
        stream=True
    )

    result = []
    for chunk in completion:
        delta = chunk.choices[0].delta
        if hasattr(delta, "content") and delta.content:
            # print(delta.content, end="", flush=True)
            result.append(delta.content)

    print('\nğŸ‘‰ è°ƒç”¨å®Œæ¯•')
    return "".join(result)


result = gpt_infer_no_image("æˆ‘åœ¨æµ‹è¯•èƒ½å¦è”é€šä½ ï¼Œè¯·è¿”å›â€œæˆåŠŸè”é€šâ€")
print(result)
